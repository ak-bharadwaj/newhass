# Production Docker Compose for 10k Concurrent Users & 1M+ Data Storage
# Usage: docker-compose -f docker-compose.yml -f docker-compose.production.yml up -d

services:
  # Add Nginx Load Balancer
  nginx:
    image: nginx:alpine
    container_name: hass_nginx_lb
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infra/nginx-loadbalancer.conf:/etc/nginx/conf.d/default.conf:ro
      # Uncomment for SSL:
      # - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend
      - frontend
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
    networks:
      - default

  # Scale backend to handle 10k concurrent
  backend:
    deploy:
      replicas: 4  # 4 backend instances for 10k users
      resources:
        limits:
          cpus: '4.0'
          memory: 4G
        reservations:
          cpus: '2.0'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    environment:
      # Production settings
      DEBUG: "False"
      WORKERS: "8"
      # Database connection pool increased
      DB_POOL_SIZE: "50"
      DB_MAX_OVERFLOW: "150"

  # Enhanced PostgreSQL for 1M+ records
  postgres:
    image: postgres:15-alpine
    command: >
      postgres
      -c max_connections=300
      -c shared_buffers=2GB
      -c effective_cache_size=6GB
      -c maintenance_work_mem=512MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=16MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
      -c max_worker_processes=8
      -c max_parallel_workers_per_gather=4
      -c max_parallel_workers=8
      -c max_parallel_maintenance_workers=4
    deploy:
      resources:
        limits:
          cpus: '8.0'
          memory: 12G
        reservations:
          cpus: '4.0'
          memory: 8G
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # Add backup volume
      - postgres_backups:/backups

  # Enhanced Redis for high concurrency
  redis:
    command: >
      redis-server
      --maxmemory 4gb
      --maxmemory-policy allkeys-lru
      --maxclients 10000
      --tcp-backlog 511
      --timeout 0
      --tcp-keepalive 300
      --save ""
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 5G
        reservations:
          cpus: '2.0'
          memory: 4G

  # Scale Celery workers
  celery_worker:
    deploy:
      replicas: 3  # 3 worker instances for background tasks
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  # Frontend with optimizations
  frontend:
    deploy:
      replicas: 2  # 2 frontend instances
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    environment:
      # Use same-origin in browser; internal URL for server-side
      NEXT_PUBLIC_API_URL: ""
      BACKEND_INTERNAL_URL: http://backend:8000

  # Add PgBouncer for connection pooling (optional but recommended)
  pgbouncer:
    image: edoburu/pgbouncer:latest
    container_name: hass_pgbouncer
    restart: unless-stopped
    environment:
      DATABASE_URL: postgres://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-hospital_db}
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 1000
      DEFAULT_POOL_SIZE: 50
      MIN_POOL_SIZE: 10
      RESERVE_POOL_SIZE: 10
      RESERVE_POOL_TIMEOUT: 5
      MAX_DB_CONNECTIONS: 200
      MAX_USER_CONNECTIONS: 200
    ports:
      - "6432:5432"
    depends_on:
      - postgres
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

volumes:
  postgres_backups:
    driver: local

networks:
  default:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1450
